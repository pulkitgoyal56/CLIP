{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize, InterpolationMode, Lambda\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rich\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAADgCAAAAADQqJxGAAACp0lEQVR4Ae2a21LDMAxEG/7/n6Fcmspraa1tzAzDLC9UlrwnOXEnPHC8337/5+33EbebIZJl67IuyYA07NNlXZIBadiny7okA9KwT5d1SQakYZ8u65IMSMM+XdYlGZCGfbqsSzIgDft0WZdkQBr26bIuyYA07NNlXZIBadiny7okA9LwXz1dxyHdxn1Yv5M7QqXIkC+ASFEhP/EaRYSc4eeHzvPRICE6fFxyJMgQPBSco0AgFkrCESBT6LRQcfqQJDJZSjltSBqYLs6cLqSIK5aB04SUYWUjcnoQEkVaJ6cFoUG0+c3pQBYxi/ad04AsQ5YDa8gyYv1+WUIajCVlBWkxVpQFpMlYUDikzeAUChEYlMIgEoNRCERkEEoNkRk1pYS8wCgpFeQlRkUpIC8yCkoOeZmRU1LIBUZKySCXGBklgVxkJJQZcpkxUybIBsZEQcgWBlIAsokBlBGyjTFSBshGxkCJkK2MSDn+6v8Ly3fM7+R47wcSJfGZnH+FPz4cN34Nj7mv3+RyGORz2xYKgXxf2g5KDXnc/gZKCXkwdhirIE/GBkoBiYzrlBwyMi5TUggyrlIyyMy4U4YvHi3m0QxCIxrNiZJApplG7jiCCTMEJ8b9vQoyJgj0e6HT1JiCkLE7bW4vDDkAGXrtxGwwJo2Q2Ml2Kmsha4CEdSWumH2mRchztdgmLp954W1xrrWz4ms93f0zECA8OwuJELY76mJzl3qGSPqsy7okA9KwT5d1SQakYZ8uSVf7HS+lwrCfCQjhpXVxP9C1LhDCS+vifqBrXSCEl9bF/UDXukAIL62L+4GudYEQXloX9wNd6wIhvLQu7ge61gVCeGld3A90rQuE8NK6uB/oWhcI4aV1cT/QtS4Qwkvr4n6ga10ghJfWxf1A9//o+gBi5BYs7D03bAAAAABJRU5ErkJggg==",
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mPIL.Image.Image\u001b[0m\u001b[39m image \u001b[0m\u001b[33mmode\u001b[0m\u001b[39m=\u001b[0m\u001b[35mL\u001b[0m\u001b[39m \u001b[0m\u001b[33msize\u001b[0m\u001b[39m=\u001b[0m\u001b[35m10\u001b[0m\u001b[1;36m0x224\u001b[0m\u001b[39m at \u001b[0m\u001b[1;36m0x7FEEB412CBE0\u001b[0m\u001b[1m>\u001b[0m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tangram = [[[0.50392557 ,0.50607443],\n",
    "            [0.32714887 ,0.50607443],\n",
    "            [0.50392557 ,0.68285113]],\n",
    "            [[0.50607443, 0.50607443],\n",
    "            [0.50607443 ,0.68285113],\n",
    "            [0.68285113 ,0.50607443]],\n",
    "            [[0.41      , 0.49392557],\n",
    "            [0.49838835 ,0.40553722],\n",
    "            [0.32161165 ,0.40553722]],\n",
    "            [[0.50553722, 0.40753722],\n",
    "            [0.50553722 ,0.49592557],\n",
    "            [0.59392557 ,0.40753722]],\n",
    "            [[0.50446278, 0.49446278],\n",
    "            [0.50446278 ,0.40607443],\n",
    "            [0.41607443 ,0.49446278]],\n",
    "            [[0.45580583, 0.31580583],\n",
    "            [0.45580583 ,0.40419417],\n",
    "            [0.54419417 ,0.40419417],\n",
    "            [0.54419417 ,0.31580583]],\n",
    "            [[0.6       , 0.49419417],\n",
    "            [0.51161165 ,0.49419417],\n",
    "            [0.6        ,0.40580583],\n",
    "            [0.68838835 ,0.40580583]]]\n",
    "\n",
    "from cv2 import fillPoly\n",
    "\n",
    "img = np.full((size := 224, 100), 255, dtype=np.uint8)\n",
    "fillPoly(img, [[-62, size] + (np.asarray(polygon) * [size, -size]).astype(int) for polygon in tangram], color=0)\n",
    "image = Image.fromarray(img)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAADgCAAAAAA/RjU9AAAEF0lEQVR4Ae2d0XbcIBBD1/3/f07dbNf1rjGDQANqjvpSxx5AV9dJTvLQbl+Pn/3n18/GezwM+L8btkEbFG/Ar6i4oDCeDYYViQ/YoLigMJ4NhhWJD9iguKAwng2GFYkP2KC4oDCeDYYViQ/YoLigMJ4NhhWJD9iguKAwng2GFYkP2KC4oDCeDYYViQ/YoLigMJ4NhhWJD9iguKAwng2GFYkP2KC4oDCeDYYViQ/YoLigMJ4NhhWJD9iguKAwng2GFYkP2KC4oDCeDYYViQ/YoLigMJ4NhhWJD9iguKAwng2GFYkP2KC4oDCeDYYViQ/YIFvQtrF3rO832+CON5dwMuA33FTCuYB/0WYSTgU8wI6L+ucP4+lMwBPW6ZJBUdljIuAb1NsHlXzDj+YBfiB9fDgMcrfBNMAL0OXGXcSx+7MACziFW2MsxdWTAIswxZvFlAM35wDeoNzcHsC5Lp0CeAty++AatPfODMAKRuVRL9HHugmAVYjqw4+sXR/mAwYIweMuqPOidMAQIBw4x8WvswEb4jeM4FzHimTApvBNQ0di8CIXsDF64xiI9hxPBWwO3jyIM2YCArGBUZAxERAKDQ0jjHmAYGRwvJkxDRAODC9oY8wC7IjbsaSBMQmwK2zXoogxB7AzaueyKmMKYHfQ7oX3jBmAAzEHlt4wJgAOhRxaXGLkAw5GHFx+YaQDDgcc3uCdkQ1IiEfY4sRIBqSEo2zyYuQCkqKRtvlmpALSgtE24v5T8MRYvK2IBnmh9neLthkPkBbp+eWBtd3m/2/i9fWW9TdLTWOeTIPbVztM2ovE+xy8NLo9gPbaq7icU7+RB/gnsgBhGuBTyXrCLMDXK7ecMAnwxbf+Lc0B/Me3nDAF8My3mjAD8J1vMWEC4CffWkI+4JVvJ6x/Mz4/BUbPy26v+YC3RzU+IBPSAcfzje9wrpINyEjH2ONgJANysnF2eTJyAVnJWPvsjFRAXi7eTkxAXiroG8vx6Va8IAIy+XiEPEAuH40Q+Hmt+AYcN3G+869hiqvPA8c56AUNsH5wCYCSv37s/pT3ioZHrRkw4JreeafaIK/LNTvZ4JreeafaIK/LNTvZ4JreeafaIK/LNTvZ4JreeafaIK/LNTvZ4JreeadO+p0MLzC6k19RtDG1eRtUM4LmsUG0MbV5G1QzguaxQbQxtXkbVDOC5rFBtDG1eRtUM4LmsUG0MbV5G1QzguaxQbQxtXkbVDOC5rFBtDG1eRtUM4LmsUG0MbV5G1QzguaxQbQxtXkbVDOC5rFBtDG1eRtUM4LmsUG0MbV5G1QzguaxQbQxtXkbVDOC5rFBtDG1eRtUM4LmsUG0MbV5G1QzguaxQbQxtXkbVDOC5rFBtDG1eRtUM4LmsUG0MbV5G1Qzgub5DYNGFixLmeGWAAAAAElFTkSuQmCC",
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mPIL.Image.Image\u001b[0m\u001b[39m image \u001b[0m\u001b[33mmode\u001b[0m\u001b[39m=\u001b[0m\u001b[35mL\u001b[0m\u001b[39m \u001b[0m\u001b[33msize\u001b[0m\u001b[39m=\u001b[0m\u001b[35m224x224\u001b[0m\u001b[39m at \u001b[0m\u001b[1;36m0x7FEEB52D95E0\u001b[0m\u001b[1m>\u001b[0m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_s = np.full((size := 224, size), 255, dtype=np.uint8)\n",
    "fillPoly(img_s, [[0, size] + (np.asarray(polygon) * [size, -size]).astype(int) for polygon in tangram], color=0)\n",
    "image_s = Image.fromarray(img_s)\n",
    "image_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3 = np.tile(img[:, :, None], (1, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.6 µs ± 6.44 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "ToTensor()(img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.89 µs ± 23.7 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.01 µs ± 19 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.asarray(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "%aimport clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mCompose\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35mResize\u001b[0m\u001b[1m(\u001b[0m\u001b[33msize\u001b[0m=\u001b[1;36m224\u001b[0m, \u001b[33minterpolation\u001b[0m=\u001b[35mbicubic\u001b[0m, \u001b[33mmax_size\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mantialias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1;35mCenterCrop\u001b[0m\u001b[1m(\u001b[0m\u001b[33msize\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m224\u001b[0m, \u001b[1;36m224\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m _convert_image_to_rgb at \u001b[0m\u001b[1;36m0x7fed1bbb7040\u001b[0m\u001b[1m>\u001b[0m\n",
       "    \u001b[1;35mToTensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1;35mNormalize\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmean\u001b[0m=\u001b[1m[\u001b[0m\u001b[1;36m0.48145466\u001b[0m \u001b[1;36m0.4578275\u001b[0m  \u001b[1;36m0.40821073\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mstd\u001b[0m=\u001b[1m[\u001b[0m\u001b[1;36m0.26862954\u001b[0m \u001b[1;36m0.26130258\u001b[0m \u001b[1;36m0.27577711\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, preprocess = clip.load('ViT-L/14')\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = ToTensor()\n",
    "cr = lambda image: image.convert(\"RGB\")\n",
    "nn = Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
    "nn255 = Normalize((122.7709383, 116.7460125, 104.09373615000001), (68.5005327, 66.6321579, 70.32316304999999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24 ms ± 25.6 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "preprocess(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.96 ms ± 66.1 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "preprocess(image.convert(\"RGB\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible inputs to preprocess\n",
    "# img\n",
    "# img3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### `broadcast_to` vs `tile` vs `repeat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147 µs ± 834 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "img3 = np.broadcast_to(img[:, :, None], img.shape + (3,)).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174 µs ± 1.32 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "img3 = np.repeat(img[:, :, None], 3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.22 µs ± 87.1 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "img3 = np.tile(img, (1, 1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.46 µs ± 380 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.tile(img, (3, 1, 1)).transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 µs ± 1.54 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.tile(img[:, :, None], (1, 1, 3))  # Tiling in the last dimension is bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (`as_tensor()` vs `tensor()`) + (`torch(np.tile(...))` vs `torch.tile(torch)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.3 µs ± 2.32 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "torch.as_tensor(np.tile(img, (3, 1, 1)), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.9 µs ± 158 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "torch.tile(torch.as_tensor(img, dtype=torch.float), (3, 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.4 µs ± 3.99 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "torch.tensor(np.tile(img, (3, 1, 1)), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.6 µs ± 9.33 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "torch.tile(torch.tensor(img, dtype=torch.float), (3, 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using `ToTensor()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163 µs ± 3.34 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "Compose([tt, nn])(np.tile((img), (3, 1, 1)).transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321 µs ± 15.8 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "Compose([tt, nn])(Image.fromarray(img).convert(\"RGB\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using `tensor()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Winner (below) - Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 µs ± 16.1 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "Compiler time: 0.14 s\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "Compose([nn255])(torch.as_tensor(np.tile(img, (3, 1, 1)), dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 µs ± 9.55 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "Compose([lambda x: torch.as_tensor(np.tile(x, (3, 1, 1)), dtype=torch.float), nn255])(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Colored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (`torch(np.transpose(...))` vs `torch.permute(torch(...))`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.8 µs ± 1.82 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "torch.as_tensor(img3.transpose(2, 0, 1), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.3 µs ± 174 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "torch.as_tensor(img3, dtype=torch.float32).permute(2, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using `ToTensor()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Winner (below) - Colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166 µs ± 4.04 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "Compose([tt, nn])(img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 µs ± 9.3 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "Compose([tt, nn])(Image.fromarray(img3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using `tensor()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186 µs ± 2.02 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "Compose([nn255])(torch.as_tensor(img3.transpose(2, 0, 1), dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mbrl_venv_cluster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
